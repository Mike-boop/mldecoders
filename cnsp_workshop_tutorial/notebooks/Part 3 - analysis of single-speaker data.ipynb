{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b9a938",
   "metadata": {},
   "source": [
    "# Notebook 3: comparison of linear and nonlinear decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy==1.7.3\n",
    "\n",
    "!git clone https://github.com/Mike-boop/mldecoders.git\n",
    "\n",
    "import os\n",
    "os.chdir('mldecoders')\n",
    "\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the predictions from the CNSP web server \n",
    "\n",
    "!wget --no-parent -r 'https://www.data.cnspworkshop.net/data/thornton_data/predictions' -O 'cnsp_workshop_tutorial/data/predictions'\n",
    "predictions_dir = 'cnsp_workshop_tutorial/data/predictions'\n",
    "# predictions_dir = 'cnsp_workshop_tutorial/data/single-speaker-predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f148f73",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "In part 1, you trained linear decoders to predict the speech envelope from EEG recordings. In part 2, each of you trained one of the DNNs for one participant's data, and sent us the predicted speech envelope values. In this notebook, we will compare the performances of the linear models with those of the DNNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8130e06",
   "metadata": {},
   "source": [
    "# Loading the predicted speech envelopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f2210",
   "metadata": {},
   "source": [
    "The outputs of the linear models which we saved can be loaded like so (using the first participant as an example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = 0\n",
    "ridge_filepath = os.path.join(predictions_dir, f\"ridge_predictions_P{participant:02d}.npy\")\n",
    "ridge_predictions = np.load(ridge_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.load(os.path.join(predictions_dir, 'ground_truth.npy'))\n",
    "print(pearsonr(ridge_predictions, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4710be",
   "metadata": {},
   "source": [
    "Similarly, the predictions of the DNNs can be loaded like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88554406",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_filepath = os.path.join(predictions_dir, f\"fcnn_predictions_P{participant:02d}.npy\")\n",
    "fcnn_predictions = np.load(fcnn_filepath)\n",
    "print(pearsonr(fcnn_predictions, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a10089",
   "metadata": {},
   "source": [
    "The time series can be compared visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3242b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_filepath = os.path.join(predictions_dir, f\"cnn_predictions_P{participant:02d}.npy\")\n",
    "cnn_predictions = np.load(cnn_filepath)\n",
    "\n",
    "fs = 125\n",
    "t = np.arange(len(cnn_predictions))/fs\n",
    "plt.plot(t, ground_truth, label='envelope')\n",
    "plt.plot(t, zscore(cnn_predictions), label='reconstruction')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(10, 30)\n",
    "plt.xlabel('Time [s]')\n",
    "\n",
    "plt.title(f'correlation: {pearsonr(ground_truth, fcnn_predictions)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec704cd",
   "metadata": {},
   "source": [
    "## Exercise: correlate the CNN predictions with the FCNN predictions. What do you notice? Also compare the DNN predictions with the predictions of the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af092f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c12f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae6141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81fd0d8b",
   "metadata": {},
   "source": [
    "# Population-level analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe50009",
   "metadata": {},
   "source": [
    "Let's collect the reconstruction accuracies (correlation coefficients) for each model and participant. We will also collect the null reconstruction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeab96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {'ridge': [], 'cnn': [], 'fcnn':[]}\n",
    "null_correlations = {'ridge': [], 'cnn': [], 'fcnn':[]}\n",
    "\n",
    "for participant in range(13):\n",
    "\n",
    "    for model in ['ridge', 'cnn', 'fcnn']:\n",
    "\n",
    "        filepath = os.path.join(predictions_dir, f\"{model}_predictions_P{participant:02d}.npy\")\n",
    "        predictions = np.load(filepath)\n",
    "\n",
    "        score = pearsonr(ground_truth, predictions)[0]\n",
    "        null_score = pearsonr(ground_truth[::-1], predictions)[0]\n",
    "\n",
    "        correlations[model].append(score)\n",
    "        null_correlations[model].append(null_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a867a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, tight_layout=True)\n",
    "\n",
    "axs[0].boxplot(correlations.values(), positions = [1,2,3])\n",
    "axs[0].set_ylabel('reconstruction score')\n",
    "axs[0].set_xticks([1,2,3])\n",
    "axs[0].set_xticklabels(correlations.keys())\n",
    "axs[0].set_ylim(-0.1, 0.4)\n",
    "\n",
    "axs[1].boxplot(null_correlations.values(), positions = [1,2,3])\n",
    "axs[1].set_ylabel('null reconstruction score');\n",
    "axs[1].set_xticks([1,2,3])\n",
    "axs[1].set_xticklabels(correlations.keys())\n",
    "axs[1].set_ylim(-0.1, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799633e",
   "metadata": {},
   "source": [
    "Clearly, the reconstruction scores are much greater than the null reconstruction scores, so we can be confident that the speech envelope reconstruction is working better than chance. Interestingly, the null reconstruction scores seem to be overall slightly negative. __Exercise: can you think of why this might be? Is this a problem?__\n",
    "\n",
    "Additionally, the two DNNs appear to perform very similarly. We should perform a quick test to see whether they are significantly better than the linear models (note that really we should be performing multiple comparison corrections here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform single-tailed paired t-tests\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "print('CNN vs ridge: p =', ttest_rel(correlations['cnn'], correlations['ridge'], alternative='greater')[1])\n",
    "print('FCNN vs ridge: p =', ttest_rel(correlations['fcnn'], correlations['ridge'], alternative='greater')[1])\n",
    "\n",
    "# additionally, compare the DNNs with a two-tailed paired t-test\n",
    "\n",
    "print('FCNN vs CNN: p =', ttest_rel(correlations['fcnn'], correlations['cnn'], alternative='two-sided')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb4917",
   "metadata": {},
   "source": [
    "# Extension: two-speaker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58039e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
