{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53d4fe1",
   "metadata": {},
   "source": [
    "# Notebook 1: Linear decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py==3.6.0\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install mne==0.24.1\n",
    "\n",
    "!git clone https://github.com/Mike-boop/mldecoders.git\n",
    "\n",
    "import os\n",
    "os.chdir('mldecoders')\n",
    "\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2079f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## placeholder cell for downloading dataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_dir = '/content/drive/MyDrive/cnsp_2022/data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display, Image\n",
    "from scipy.signal import hilbert\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mne.filter import filter_data\n",
    "import h5py\n",
    "from pipeline.ridge import Ridge\n",
    "import pickle\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486008b",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "In this tutorial we will be using EEG data that was recorded whilst a participant attended to continuous speech (in the form of audiobooks). Below is an example of a typical experimental setup used to acquire this sort of data, as well as an example audiobook from our dataset.\n",
    "\n",
    "<img src=\"../images/cnsp_experiment.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f21324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_file = 'cnsp_workshop_tutorial/data/AUNP01.wav'\n",
    "srate, speech = wavfile.read(sound_file)\n",
    "wn = Audio(sound_file, autoplay=True, rate=srate)\n",
    "display(wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe943242",
   "metadata": {},
   "source": [
    "We can study what features of the stimulus are encoded in the EEG recordings by attempting to reconstruct (or decode) them:\n",
    "\n",
    "<img src=\"../images/cnsp_bw_model.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e546fb",
   "metadata": {},
   "source": [
    "The speech envelope (essentially the amplitude) turns out to be rather strongly encoded in EEG recordings. You can see how the speech envelope relates the the original waveform below:m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5126d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_envelope(x, fs):\n",
    "    envelope = np.abs(hilbert(x))\n",
    "    return filter_data(envelope, fs, None, 50)\n",
    "\n",
    "t = np.arange(len(speech))/srate\n",
    "plt.plot(t, speech, label = 'speech')\n",
    "plt.plot(t, get_envelope(speech, srate), label = 'speech envelope')\n",
    "plt.xlim(0, 10)\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude [au]')\n",
    "plt.title('Plot of stimulus and stimulus envelope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2599aa12",
   "metadata": {},
   "source": [
    "In the linear decoding approach, we take a linear combination (or weighted sum) of the EEG recordings within a certain time window in order to predict the speech envelope at the start of the window:\n",
    "\n",
    "<img src=\"../images/cnsp_maths.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117423d5",
   "metadata": {},
   "source": [
    "The traditional method for finding the optimal weights/parameters is ridge regression. This is implemented in popular toolboxes such as the mTRF toolbox and mne-Python. We also provide an implementation which will be explored in this notebook. The famous formula for the ridge parameters is as follows:\n",
    "\n",
    "<img src=\"../images/cnsp_ridge.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794bed4",
   "metadata": {},
   "source": [
    "# Data, availability, and preprocessing\n",
    "\n",
    "In the tutorial we will use EEG data recorded from 13 participants. Each participant listened to a single speaker narrate audiobook chapters in English. There were 15 trials per participant. Full details of the data acquisition procedure are given in [Hugo's paper](https://direct.mit.edu/jocn/article-abstract/32/1/155/95401/Cortical-Tracking-of-Surprisal-during-Continuous).\n",
    "\n",
    "A version of this dataset is freely available on [figshare](https://figshare.com/projects/Cortical_Tracking_of_Surprisal_during_Continuous_Speech_Comprehension/66596). If you are interested in using the unprocessed dataset for your research, feel free to contact me at mdt20@ic.ac.uk. We plan to release the unprocessed recordings, as well as another dataset with more interesting stimuli, in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b86c60",
   "metadata": {},
   "source": [
    "The EEG data used in this tutorial has already been preprocessed. You can find details of the preprocessing procedure in our paper, as well as in the `data_preprocessing` directory in this repository. The sampling rate of the preprocessed data is 125 Hz, and the EEG data have been filtered between 0.5 Hz and 8 Hz. We have used broadband stimulus envelopes, lowpass filtered below 50 Hz.\n",
    "\n",
    "The frequency ranges of the data are verified for one of the participants below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b39c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_dir, 'r') as f:\n",
    "    eeg = f['eeg/P00/part1'][:]\n",
    "    envelope = f['stim/part1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b756ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "for i in range(63): \n",
    "    axs[0].psd(eeg[i], Fs=125);\n",
    "    \n",
    "axs[1].psd(envelope, Fs=125);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be5c5e",
   "metadata": {},
   "source": [
    "# Linear models\n",
    "\n",
    "We would like to relate the EEG recordings to the speech envelopes. One way of doing this is via backward modelling, otherwise known is stimulus-reconstruction. We will begin by using an approach which is similar to the TRF model, but predicts the speech envelope given a temporal context of EEG recordings using a linear filter.\n",
    "\n",
    "We will fit the linear filter via ridge regression, which is common practice in the field. We will use the first nine story parts as training data, the next 3 as validation data for tuning the regularisation parameter, and the final 3 as testing data. We could also have chosen to perform cross-validation here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d06739",
   "metadata": {},
   "source": [
    "## Fitting a linear model for a single participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9c880",
   "metadata": {},
   "source": [
    "First, we go over fitting a linear model in detail, for a single participant. We choose the first participant (0) by default.\n",
    "\n",
    "We will use nine EEG trials to fit the model parameters via ridge regression. Three trials will be used for 'validation' - that is, for choosing the regularisation hyperparameter $\\lambda$. The remaining three trials will be used to evaulate the fit with the chosen hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c371330",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = 0\n",
    "\n",
    "train_parts = range(3)\n",
    "val_parts = range(9,12)\n",
    "test_parts = range(12, 15)\n",
    "\n",
    "# try 15 regularisation parameters spaced evenly on a log scale between 1e-7 and 1e7\n",
    "regularisation_parameters = np.logspace(-7, 7, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1a16b",
   "metadata": {},
   "source": [
    "Concatenating the trials in the training, validation, and testing datasets, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_dir, 'r') as f:\n",
    "    X_train = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in train_parts])\n",
    "    y_train = np.hstack([f[f'stim/part{j}'][:] for j in train_parts])\n",
    "    \n",
    "    X_val = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in val_parts])\n",
    "    y_val = np.hstack([f[f'stim/part{j}'][:] for j in val_parts])\n",
    "    \n",
    "    X_test = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in test_parts])\n",
    "    y_test = np.hstack([f[f'stim/part{j}'][:] for j in test_parts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c8fc4",
   "metadata": {},
   "source": [
    "To fit the model, we have to state the number of lags used in the spatiotemporal window, which is 50 in this case. Note that since the sampling rate is 125 Hz, this corresponds to a window duration of about 0.4 s.\n",
    "\n",
    "We can also set an offset between the start of the window and the predicted envelope value, which is defined by `start_lag`. This is set to zero here, since we assume causality. This parameter is useful for fitting encoding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38adbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the model\n",
    "mdl = Ridge(start_lag=0, end_lag=50, alpha=regularisation_parameters)\n",
    "\n",
    "# fit the model parameters via ridge regression, for all regularisation parameters\n",
    "mdl.fit(X_train.T, y_train[:, np.newaxis])\n",
    "\n",
    "# evaluate the model on the validation dataset for every regularisation parameter, and select the best value\n",
    "val_scores = mdl.model_selection(X_val.T, y_val[:, np.newaxis])\n",
    "\n",
    "# test the model on the test dataset\n",
    "test_score = mdl.score(X_test.T, y_test[:, np.newaxis])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regularisation_parameters, val_scores)\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.title('Reconstruction accuracies for validation dataset')\n",
    "plt.ylabel('Validation score (Pearson r)')\n",
    "plt.xlabel('Regularisation parameter')\n",
    "\n",
    "print('Best regularisation parameter: ', mdl.alphas[mdl.best_alpha_idx])\n",
    "print('Test score (correlation):', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098da26",
   "metadata": {},
   "source": [
    "## Fitting linear models for all participants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d95800",
   "metadata": {},
   "source": [
    "Now we're ready to fit linear decoders for all of the participants! In the following cell, you can also see how the trained linear models and their predictions are saved to disk for use later. We also obtain 'null scores', which are explained next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d7b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "null_scores = []\n",
    "\n",
    "with h5py.File(data_dir, 'r') as f:\n",
    "    \n",
    "    mdl = Ridge(start_lag=0, end_lag=50, alpha=regularisation_parameters)\n",
    "\n",
    "    for participant in range(13):\n",
    "        \n",
    "        print('Fitting model for participant:', participant)\n",
    "        \n",
    "        # training using all regularisation parameters\n",
    "        X_train = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in train_parts])\n",
    "        y_train = np.hstack([f[f'stim/part{j}'][:] for j in train_parts])\n",
    "        mdl.fit(X_train.T, y_train[:, np.newaxis])\n",
    "        \n",
    "        # select best regularisation parameter\n",
    "        X_val = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in val_parts])\n",
    "        y_val = np.hstack([f[f'stim/part{j}'][:] for j in val_parts])\n",
    "        val_scores = mdl.model_selection(X_val.T, y_val[:, np.newaxis])\n",
    "        \n",
    "        # save the trained model\n",
    "        pickle.dump(mdl, open(f\"cnsp_workshop_tutorial/results/linear_models/P{participant:02d}_ridge.pk\", \"wb\"))\n",
    "        \n",
    "        # get and save predicted speech envelope\n",
    "        X_test = np.hstack([f[f'eeg/P0{participant}/part{j}'][:] for j in test_parts])\n",
    "        y_test = np.hstack([f[f'stim/part{j}'][:] for j in test_parts])\n",
    "        \n",
    "        test_predictions = mdl.predict(X_test.T)\n",
    "        np.save(f\"cnsp_workshop_tutorial/results/linear_models/P{participant:02d}_predictions.npy\", test_predictions)\n",
    "        \n",
    "        # compute the correlation between the predictions and the true speech envelope\n",
    "        test_score = mdl.score(X_test.T, y_test[:, np.newaxis])[0]\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        # compute the null correlations\n",
    "        null_score = mdl.score(X_test.T, y_test[::-1, np.newaxis])[0]\n",
    "        null_scores.append(null_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f31ddf",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "In the last two lines of the above cell, we computed 'null scores' by time-reversing the true speech envelope and correlating it against the predicted speech envelope. Since there should be no systematic correlation between the predicted speech envelope and the time-reversed speech envelope, the resulting 'null scores' allow us to estimate the noise level of the reconstruction scores (Pearson correlation coefficients). This allows us to assess whether the reconstruction scores are due to chance correlations, or whether the speech envelope really can be decoded from the EEG recordings.\n",
    "\n",
    "The reconstruction scores and null scores for each participant are plotted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = .2\n",
    "x = np.arange(13)\n",
    "plt.bar(x-width/2, test_scores, width=width, label='correlations')\n",
    "plt.bar(x+width/2, null_scores, width=width, label='null correlations')\n",
    "\n",
    "plt.title(\"Correlation coefficients between the predicted and actual speech envelopes\")\n",
    "plt.ylabel('Reconstruction score (Pearson)')\n",
    "plt.xlabel(\"Participant\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4053bf",
   "metadata": {},
   "source": [
    "We should check that the reconstruction scores are significantly different to the null distribution. We can do this with a t-test. The p-value turns out to be quite significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ee2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "print(ttest_ind(test_scores, null_scores, alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d96db1",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e0da0",
   "metadata": {},
   "source": [
    "## 1. Find regularisation curves for each of the 13 participants.\n",
    "\n",
    "The regularisation curve is a plot of validation score (Pearson's correlation coefficient) against regularisation parameter, as shown above. __To speed things up, you may wish to reduce the amount of training data. Using just the first three trials should be ok__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204678a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c7672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81e2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49fe73f6",
   "metadata": {},
   "source": [
    "## 2. Questions about the regularisation curves:\n",
    "\n",
    "- What is the mean optimal regularisation parameter?\n",
    "- Is the optimal regularisation parameter the same for all participants?\n",
    "- What do you notice about the regularisation curves for small and large values of the regularisaiton parameter? Can you explain this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4bded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc32ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08155a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39782c0f",
   "metadata": {},
   "source": [
    "## 3. (Extension) Try fitting forward models using the Ridge class. You'll need to change the `start_lag` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cce612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
